{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Framework Modulaire de Reconnaissance de Signes (SLR)\n",
                "\n",
                "Ce notebook démontre l'utilisation de l'architecture modulaire `src/`.  \n",
                "Il permet de comparer facilement différentes stratégies de **prétraitement** (ex: segmentation de peau) et différentes **architectures de modèles**.\n",
                "\n",
                "Cette architecture est **agnostique** au dataset utilisé. Elle peut être configurée pour l'alphabet ASL, LSF, ou tout autre dataset d'images classées par dossiers.\n",
                "\n",
                "## Structure du Projet\n",
                "- `src.config`: Configuration centralisée (supporte plusieurs environnements)\n",
                "- `src.preprocessing`: Algorithmes de segmentation (HSV, etc.)\n",
                "- `src.data`: Pipeline de chargement dynamique\n",
                "- `src.model`: SignCNN (Modèle Générique) et MobileNetV2\n",
                "- `src.train`: Moteur d'entraînement"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.metrics import confusion_matrix, classification_report\n",
                "import cv2\n",
                "import numpy as np\n",
                "\n",
                "# Import des modules locaux\n",
                "from src.config import config\n",
                "from src.data import get_dataloaders\n",
                "from src.model import get_model, SignCNN\n",
                "from src.train import Trainer\n",
                "from src.preprocessing import HSVSkinSegmenter, NoOpPreprocessor\n",
                "\n",
                "print(config)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Choix de la Stratégie de Segmentation\n",
                "C'est ici que réside la modularité du prétraitement. Vous pouvez choisir entre :\n",
                "- `NoOpPreprocessor`: Aucune segmentation (Baseline)\n",
                "- `HSVSkinSegmenter`: Segmentation par couleur de peau HSV"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CHOIX DE L'EXPÉRIENCE\n",
                "USE_SEGMENTATION = True\n",
                "\n",
                "if USE_SEGMENTATION:\n",
                "    print(\"✅ Activation de la Segmentation HSV (Peau)\")\n",
                "    # Vous pouvez ajuster les seuils HSV ici si nécessaire\n",
                "    preprocessor = HSVSkinSegmenter(lower_hsv=[0, 20, 70], upper_hsv=[20, 255, 255])\n",
                "else:\n",
                "    print(\"❌ Pas de segmentation (Raw Images)\")\n",
                "    preprocessor = NoOpPreprocessor()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Chargement des Données\n",
                "Le `preprocessor` est injecté dans le pipeline de transformation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Vous pouvez surcharger config.DATA_DIR ici si vous utilisez un autre dataset (ex: LSF)\n",
                "# config.DATA_DIR = \"/chemin/vers/lsf_dataset\"\n",
                "\n",
                "train_loader, val_loader, class_names = get_dataloaders(preprocessor=preprocessor)\n",
                "config.NUM_CLASSES = len(class_names)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Visualisation des Données (Après Preprocessing)\n",
                "Vérifions à quoi ressemblent les images qui entrent dans le réseau."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torchvision\n",
                "\n",
                "def imshow(inp, title=None):\n",
                "    \"\"\"Affichage d'un tenseur image\"\"\"\n",
                "    inp = inp.numpy().transpose((1, 2, 0))\n",
                "    mean = np.array([0.485, 0.456, 0.406])\n",
                "    std = np.array([0.229, 0.224, 0.225])\n",
                "    inp = std * inp + mean\n",
                "    inp = np.clip(inp, 0, 1)\n",
                "    plt.imshow(inp)\n",
                "    if title:\n",
                "        plt.title(title)\n",
                "    plt.axis('off')\n",
                "\n",
                "# Récupération d'un batch\n",
                "inputs, classes = next(iter(train_loader))\n",
                "out = torchvision.utils.make_grid(inputs[:4])\n",
                "\n",
                "plt.figure(figsize=(10, 5))\n",
                "imshow(out, title=[class_names[x] for x in classes[:4]])\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Configuration du Modèle et Entraînement\n",
                "Choix possible : `'custom'` (SignCNN) ou `'mobilenet_v2'`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = get_model(model_name=\"custom\", num_classes=config.NUM_CLASSES)\n",
                "\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer = optim.Adam(model.parameters(), lr=config.LEARNING_RATE)\n",
                "\n",
                "trainer = Trainer(model, {'train': train_loader, 'val': val_loader}, criterion, optimizer)\n",
                "\n",
                "# Entraînement\n",
                "model, history = trainer.train(epochs=config.EPOCHS)\n",
                "trainer.save_model(\"final_model.pth\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Analyse des Performances"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Courbes d'apprentissage\n",
                "plt.figure(figsize=(12, 5))\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.plot(history['train_loss'], label='Train Loss')\n",
                "plt.plot(history['val_loss'], label='Val Loss')\n",
                "plt.legend()\n",
                "plt.title(\"Loss Evolution\")\n",
                "\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.plot(history['train_acc'], label='Train Acc')\n",
                "plt.plot(history['val_acc'], label='Val Acc')\n",
                "plt.legend()\n",
                "plt.title(\"Accuracy Evolution\")\n",
                "plt.show()\n",
                "\n",
                "# Matrice de Confusion\n",
                "print(\"Génération de la Matrice de Confusion...\")\n",
                "all_preds = []\n",
                "all_labels = []\n",
                "\n",
                "model.eval()\n",
                "with torch.no_grad():\n",
                "    for inputs, labels in val_loader:\n",
                "        inputs = inputs.to(config.DEVICE)\n",
                "        outputs = model(inputs)\n",
                "        _, preds = torch.max(outputs, 1)\n",
                "        all_preds.extend(preds.cpu().numpy())\n",
                "        all_labels.extend(labels.numpy())\n",
                "\n",
                "plt.figure(figsize=(12, 10))\n",
                "cm = confusion_matrix(all_labels, all_preds)\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
                "plt.ylabel('Vraie Classe')\n",
                "plt.xlabel('Classe Prédite')\n",
                "plt.show()\n",
                "\n",
                "print(classification_report(all_labels, all_preds, target_names=class_names, labels=range(len(class_names))))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}